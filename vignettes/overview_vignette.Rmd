---
title: "A Brief Overview of EyetrackingR"
author: "Jacob Dink & Brock Ferguson"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This vignette will use the entire *eyetrackingR* toolbox to analyze real data from a simple 2-alternative forced choice (2AFC) word recognition task administered to 19- and 24-month-olds.

On each trial, infants were shown a picture of an animate object (e.g., a horse) and an inanimate object (e.g., a spoon). After inspecting the images, they disappeared and they heard a label referring to one of them (e.g., "The horse is nearby!"). Finally, the objects re-appeared on the screen and they were prompted to look at the target (e.g., "Look at the horse!").

We want to ask whether infants looked to the named target. That is, when the animate was named, did they look at the animate? And, when the inanimate was named, did they look at the inanimate?

## Load dataset and dependencies

```{r}
load('../data/word_recognition.rda')

library(ggplot2)
```

## Load and set data options for **eyetrackingR** library.

Each data option specifies the name of a column (or columns, in the case of `aoi_columns`) in your dataset.

```{r results='hide'}
library("eyetrackingR")

# set data options
data_options = set_data_options( 
  trial_column = "Trial",
  time_column = "TimeFromTrialOnset",
  trackloss_column = "TrackLoss",
  aoi_columns = c('Animate','Inanimate'),
  participant_column = "ParticipantName"
)
```

## Verify state of each relevant column.

If any of our columns are improperly formatted, this function will (1) notify us and, (2) attempt to fix it.

```{r}
data <- verify_dataset(word_recognition, data_options)
```

## Subset data to examine "response" window, and deal with trackloss.

These functions span a host of data preparation steps. Here's what we are going to do:

1) Subset the data to focus on our time window of interest (a "response window" beginning 500ms pre-word-onset, 15500ms after the start of the trial, and ending at the end of the trial 5500ms later)
2) Treat looks outside of our AOIs as if they are trackloss (we don't care if infants looked at the screen unless they were looking at one of our AOIs)
3) Calculate the amount of trackloss in each trial
4) Remove trials with over 50% trackloss
5) Remove all remaining trackloss samples from our dataset (so that, in each sample, the infant is looking either to one AOI or the other)

```{r}
# subset to response window
response_window <- subset_by_window(data, data_options, window_start_time = 15500, window_end_time = 21000, rezero = FALSE)

# convert non-AOI looks to trackloss
response_window <- convert_non_aoi_to_trackloss(response_window, data_options)

# analyze amount of trackloss by subjects and trials
trackloss <- trackloss_analysis(data = response_window,
                                data_options = data_options)

# show trackloss
trackloss

response_window_clean <- clean_by_trackloss(data = response_window,
                                            data_options = data_options, 
                                            trial_prop_thresh = .25)

# remove all trackloss from remaining trials
response_window_clean <- remove_trackloss(response_window_clean, data_options, delete_rows=TRUE)
```

## Create "Target" condition based on TrialName

```{r}
# create "Target" condition column based on trial names
response_window_clean$Target <- ifelse(grepl('(Spoon|Bottle)', response_window_clean$Trial), 'Inanimate', 'Animate')
response_window_clean$Target <- factor(response_window_clean$Target)
```

## Describe and visualize results

Summarize the data such that, for each subject, we have a mean proportion of looking to the `Animate` AOI for each type of `Target` trial within our response window.

```{r}
(data_summary <- describe_data(response_window_clean, data_options, describe_column='Animate', group_columns=c('ParticipantName','Target')))
```

Collapse across subjects within a series of 100ms time-bins, and plot the timecourse of looking.

```{r}
# aggregate across trials within subjects in time analysis
response_time <- make_time_sequence_data(response_window_clean, data_options, time_bin_size = 100, 
                                 predictor_columns = c("Target"),
                                 aoi = c("Animate")
                            )

# visualize time results
plot(response_time, predictor_column = "Target") + 
  ylab("Proportion Looking to Animate") + theme_light() +
  coord_cartesian(ylim = c(0,1))
```

Aggregate across our response window for each subject, calculating a mean proportion of looking to the `Animate` AOI for each type of `Target` trial.

```{r}
# aggregate by subject across the response window
response_window_agg_by_sub <- make_time_window_data(response_window_clean, 
                                             data_options, 
                                             aois='Animate',
                                             predictor_columns=c('Target','Age','MCDI_Total'),
                                             summarize_by = "ParticipantName")

# take a quick peek at data
plot(response_window_agg_by_sub, predictor_columns="Target")

# show condition means
describe_data(response_window_agg_by_sub, describe_column = "Prop", group_columns = "Target")
```

## Simple paired t-test

Perform a simple t-test on the condition means within each subject.

```{r}
# simple t-test between conditions
t.test(ArcSin ~ Target, data=response_window_agg_by_sub, paired=TRUE)
```

## Mixed-effects model windowed data

Create a trial-by-trial dataset (*not* summarizing across participants) and then fit a linear mixed-effects model using `lmer` predicting infants' looking to the `Animate` AOI based on the `Target` condition of each trial while accounting for random intercept and slope across `Trial` (i.e., items) and `ParticipantName` (i.e., subjects).

```{r}
library("lme4")
response_window_agg <- make_time_window_data(response_window_clean, 
                                             data_options, 
                                             aois='Animate', 
                                             predictor_columns=c('Target','Age','MCDI_Total'))

# mixed-effects linear model on subject*trial data
response_window_agg$TargetC <- ifelse(response_window_agg$Target == 'Animate', .5, -.5)
response_window_agg$TargetC <- scale(response_window_agg$TargetC, center=TRUE, scale=FALSE)

model <- lmer(Elog ~ TargetC + (1 + TargetC | Trial) + (1 | ParticipantName), 
              data = response_window_agg, REML = FALSE)
summary(model)
drop1(model,~.,test="Chi")
```

## Growth curve analysis

Take advantage of the `response_time` dataframe's orthogonal polynomial timecodes to perform a growth curve analysis. Plot the growth curve model's best fit alongside the raw data's means.

```{r}
# growth curve analysis on time series
response_time$TargetC <- ifelse(response_time$Target == 'Animate', .5, -.5)
response_time$TargetC <- scale(response_time$TargetC, center=TRUE, scale=FALSE)

model <- lmer(Elog ~ TargetC*(ot1 + ot2 + ot3 + ot4 + ot5) + (1 | Trial) + (1 | ParticipantName), 
              data = response_time, REML = FALSE)
summary(model)
drop1(model,~.,test="Chi")

# visualize GCA model
ggplot(response_time, aes(x=Time, y=Elog, color=Target)) +
  stat_summary(fun.y=mean, geom="point") +
  stat_summary(aes(y=predict(model,response_time,re.form=NA)), 
               fun.y=mean, geom="line", linetype='solid', size=2)
```

## Onset-contingent analysis

Compare the time it took for infants to switch to a new AOI depending on:

* whether they began the trial looking at the Target or not and,
* which type of trial they were participating in (i.e., whether the target was the Animate or the Inanimate)

The size of the gap between the solid line (switching from the non-Target) and the dashed line (switching from the Target) documents infants' performance in identifying the target: Infants should switch more quickly and more frequently *to* the Target than *from* it (but they also may be hesitant to *ever* shift from their preferred, animate targets...).

```{r}
# recode AOIs to target & distractor
response_window_clean$TrialTarget <- 
  ifelse(response_window_clean$Target == 'Animate', response_window_clean$Animate, response_window_clean$Inanimate)
response_window_clean$TrialDistractor <- 
  ifelse(response_window_clean$Target == 'Animate', response_window_clean$Inanimate, response_window_clean$Animate)

onsets <- make_onset_data(response_window_clean, data_options, onset_time = 15500, fixation_window_length = 100, target_aoi='TrialTarget')

plot(onsets, predictor_columns = "Target") + theme(legend.text=element_text(size=5))

# compare switch times in a mixed-effects model
onset_switches <- make_switch_data(onsets, predictor_columns = "Target")

# visualize subject's switch times
plot(onset_switches, predictor_columns = "Target") 

# center predictor:
onset_switches$FirstAOIC <- ifelse(onset_switches$FirstAOI == 'TrialTarget', .5, -.5)
onset_switches$FirstAOIC <- scale(onset_switches$FirstAOIC, center=TRUE, scale=FALSE)
onset_switches$TargetC <- ifelse(onset_switches$Target == 'Animate', .5, -.5)
onset_switches$TargetC <- scale(onset_switches$TargetC, center=TRUE, scale=FALSE)

model <- lmer(FirstSwitch ~ FirstAOIC*TargetC + 
                (1 | Trial) + (1 | ParticipantName), data=onset_switches, REML=FALSE)
summary(model)
drop1(model,~.,test="Chi")
```

## Bootstrapped splines analysis

Resample smoothing splines fit to the data to estimate the best-fitting smoothing spline with 95% confidence intervals. This is a useful technique for estimating the timepoints of divergence between two-conditions while smoothing over minor deviations in fixations. Returns a list of divergences between your two conditions based on time windows in which the 95% confidence intervals did not include 0 (i.e., *p* < .05).

```{r}
bootstrapped_familiar <- make_boot_splines_data(response_time, 
                                                predictor_column = 'Target', 
                                                within_subj = TRUE, 
                                                samples = 1000, 
                                                resolution = 100, 
                                                alpha = .05, 
                                                smoother = 'smooth.spline') 

plot(bootstrapped_familiar)

bootstrap_analysis_familiar <- analyze_boot_splines(bootstrapped_familiar)

# same as above, because, for within-subjects data, it always plots the difference score estimates
#plot(bootstrap_analysis_familiar) 

summary(bootstrap_analysis_familiar)
```


## Bootstrapped cluster analysis

Perform a different type of bootstrapping analyses (Maris & Oostenveld, 2007) referred to as a cluster analysis. This analysis takes a summed statistic for each cluster of time bins that pass some level of significance, and compares each to the "null" distribution of sum statistics (obtained by bootstrap resampling data within the largest of the clusters).

This type of analysis should often give similar results to the above, with the main advantage is that it can be used with several types of statistical techniques (`t.test`, `wilcox.test`, `lm`, and `lmer`), so that continuous predictors, covariates, etc. can be included in the model being tested; and the main disadvantage is that it is slower.

```{r}
response_time_by_subj <- make_time_sequence_data(response_window_clean, data_options, time_bin_size = 225, 
                                 predictor_columns = c("Target"),
                                 aois = c("Animate"), 
                                 summarize_by = "ParticipantName"
                            )

df_timeclust = make_time_cluster_data(response_time_by_subj, 
                                      test= "t.test", paired = TRUE,
                                      predictor_column = "Target", 
                                      threshold = 2.5) # <--- just to make things more challenging
plot(df_timeclust) +
  ylab("T-Statistic")
summary(df_timeclust)

clust_analysis = analyze_time_clusters(df_timeclust, within_subj = TRUE, paired=TRUE, samples=500)
clust_analysis

plot(clust_analysis) 
```





