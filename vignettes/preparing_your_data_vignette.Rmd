---
title: "Preparing your data for use with eyetrackingR"
author: "Jacob Dink & Brock Ferguson"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

> **Our Experiment**: Each eyetrackingR vignette uses the *eyetrackingR* package to analyze real data from a simple 2-alternative forced choice (2AFC) word recognition task administered to 19- and 24-month-olds.
> On each trial, infants were shown a picture of an animate object (e.g., a horse) and an inanimate object (e.g., a spoon). After inspecting the images, they disappeared and they heard a label referring to one of them (e.g., "The horse is nearby!"). Finally, the objects re-appeared on the screen and they were prompted to look at the target (e.g., "Look at the horse!").

## Overview of this vignette

This vignette will cover the basics of preparing your data for use with eyetrackingR.

eyetrackingR is quite flexible. It will work any eye-tracking dataset that includes the following columns with the following values:

* **Participant Columns:** Specifies the unique code for each participant (e.g., 'SUBJ101')
* **Trial Columns:** Specifies the unique name or number of each trial. For experiments in which each subject sees each item only once, this can be either a name (e.g., 'HORSE-DOG') or a number (e.g., trial 1, 2, 3, etc.). But if trials see items multiple times, this will almost always be a number.
* **Timestamp Column:** Specifies the cumulative time passed within each trial (e.g., in milliseconds: 0, 50, 100, ..., 1500). This column specifies the time-within-trial. If you have a timestamp column, but the beginning of the timestamp doesn't correspond to the beginning of the trial in the way you'd like, the function `subset_by_window` can help fix this.
* **AOI Column(s):** These columns specify whether the gaze is in a particular 'Area of Interest.' Each AOI should have a corresponding column. The elements of this column specify, for each sample, whether the participant's gaze was in that AOI. If you don't have columns like this, the function `add_aoi` can create them.

There are also some optional columns, which you might want to use depending on your analysis:

* **Item column(s):** This corresponds to any 'items' in your experiment: types of stimuli presented across trials. This is likely to always be a name (e.g., 'HORSE-DOG') and, unlike the 'Trial' column, this does not need to be unique.
* **Miscellaneous predictor column(s):** These are columns specifying predictors (e.g., Condition, Age, Sex). Unlike the types above, these are specified separately for each analysis (and not within `set_data_options` at the outset).

If your dataset has these columns (which most should...), you're ready to begin using eyetrackingR.

## Data Preparation

### Load dataset and dependencies, set data options for eyetrackingR.

Before being used in eyetrackingR, data must be run through the `make_eyetrackingr_data` function. 

This lets you provide the information about your dataset that was just described above. The function will perform some checks on your data to make sure it's in the correct format.

For this dataset, because each participant saw each item only once in this experiment, `trial_column` specifies a unique name for each trial (e.g., "FamiliarCow") and we don't specify an `item_column`.

```{r results='hide'}
set.seed(42)

library("Matrix")
library("lme4")
library("ggplot2")
library("eyetrackingR")

data("word_recognition")
data <- make_eyetrackingr_data(word_recognition, 
                       participant_column = "ParticipantName",
                       trial_column = "Trial",
                       time_column = "TimeFromTrialOnset",
                       trackloss_column = "TrackLoss",
                       aoi_columns = c('Animate','Inanimate'),
                       treat_non_aoi_looks_as_missing = TRUE
)
```

### Dealing with Non-AOI Looks

You might be wondering about the `treat_non_aoi_looks_as_missing` argument above.

Almost all eyetracking analyses require calculating proportion looking--across a trial, within a time bin, etc. One important choice you as the researcher have to make is whether to include non-AOI looking in this calculation. There are two options:

* **Treat Non-AOI Looks as Missing Data.** For many visual world paradigms, this move reflects the assumption that looking to a blank portion of the screen might as well be considered trackloss. The main advantage to this technique is that it makes analyses focusing on the tradeoff between two or more AOI more easily interpretable. Without treating outside looks as trackloss, it can be difficult to interpret an increase in looking to a single AOI across conditions. Was this due to an overall increase in attention (that is, looking to _all_ AOIs, including the one of interest, increased)? Or due to an increase in preference for that AOI specifically? 
* **Treat Non-AOI Looks as Valid Data** The tradeoff with the above is that, if we are interested in overall attention to all AOIs across conditions, then the previous approach will obscure this difference. So the alternative is to treat non-AOI looks as valid. 

The argument `treat_non_aoi_looks_as_missing` lets you decide which of these options eyetrackingR will do. If set to TRUE, when it comes time for eyetrackingR to calculate proportion looking to an AOI, this will be calculated as "time looking to that AOI divided by time looking to all other AOIs." In contrast, if this parameter is set to FALSE, proportion looking to an AOI will be calculated as "time looking to that AOI divided by total time looking."

### Subset data to a relevant window

When preparing our data for analysis, we typically want to focus on a particular window in the trial. 

* If we're lucky, this just means using the same start and end time for each trial. 
* If we're unlucky, this means using unique stimulus-presentation timestamps for each trial. 

eyetrackingR lets us handle both types of data. However, our dataset below is the 'lucky' version. 

Here, we subset the data to focus on our time window of interest (a "response window" beginning 500ms pre-word-onset, 15500ms after the start of the trial, and ending at the end of the trial 5500ms later)

```{r, warning=FALSE}
# subset to response window
response_window <- subset_by_window(data, 
                                    window_start_time = 15500, 
                                    window_end_time = 21000, 
                                    rezero = FALSE)
```

## Dealing with trackloss

Trackloss occurs when the eye-tracker loses track of the participant's eyes (e.g., when they turn away or blink) or when it captures their gaze location but with very low validity.

We need to decide which trials to remove (if any) due to very high trackloss. To do so here, we will:

* Calculate the amount of trackloss in each trial
* Remove trials with over 25% trackloss

```{r, warning=FALSE}
# analyze amount of trackloss by subjects and trials
(trackloss <- trackloss_analysis(data = response_window))

response_window_clean <- clean_by_trackloss(data = response_window, trial_prop_thresh = .25)
```

## Create additional columns needed for analysis

Now is the time to make sure that we have all the columns needed for our analyses, because this dataset is going to be shaped and subsetted as we analyze our data and it's easier to add these columns once then to do it for derivative datasets.

For the present experiment, one thing we want to do is create a "Target" condition column based on the name of each Trial.

In each trial, the participant was told to look at either an Animate or Inanimate objects. Here we create a column specifying which for each column.

```{r, warning=FALSE}
response_window_clean$Target <- as.factor( ifelse(test = grepl('(Spoon|Bottle)', response_window_clean$Trial), 
                                       yes = 'Inanimate', 
                                       no  = 'Animate') )
```

Our dataset is now ready for analysis!