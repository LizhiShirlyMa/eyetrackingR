---
title: "Testing Properties of Divergence Analyses with Simulations"
author: "Jacob Dink"
date: "November 15, 2015"
output: html_document
---

### Notes/Brainstorming:

wrap each of the tests below in a for loop that varies
* sample-size (both subjects, items)
* effect-size
* length of trial

other things to check:
[x] Any divergence?
[x] Total prop of divergence time?
[ ] Magnitude of divergence?
[ ] Average distance between cluster and bootstrapped? 

### Example Fake Data with No Effect

No preference for either AOI (5 second trial, N=16, 6 items per participant, between subjects)

```{r}
library("eyetrackingR")
library("ggplot2")
library("dplyr")
library("pbapply")

set.seed(40)
tb_size = 250

df <- simulate_eyetrackingr_data()
describe_data(df, describe_column = "AOI1", group_columns = c("Condition","Participant","Item"))
df_time <- make_time_sequence_data(df, time_bin_size = tb_size, predictor_columns = "Condition", aois = "AOI1")
plot(df_time, predictor_column = "Condition")

##
ggplot(df_time, aes(x = Time, y = Prop, group = Condition, color=Condition)) +
  stat_summary(fun.y = mean, geom="line") +
  facet_wrap(~ Participant)

ggplot(df_time, aes(x = Time, y = Prop, group = Condition, color=Condition)) +
  stat_summary(fun.y = mean, geom="line") +
  facet_wrap(~ Item)

num_time_bins <- length(unique(df_time$TimeBin))
```

### Example Fake Data with Effect

A strong preference for AOI1 in the "high" condition emerges halfway through the trial (5 second trial, N=16, 6 items per participant, between subjects).

```{r}
set.seed(50)
df <- simulate_eyetrackingr_data(pref = .80, pref_window = c(2500,5000))
df_time <- make_time_sequence_data(df, time_bin_size = tb_size, predictor_columns = "Condition", aois = "AOI1")
plot(df_time, predictor_column = "Condition")

##
ggplot(df_time, aes(x = Time, y = Prop, group = Condition, color=Condition)) +
  stat_summary(fun.y = mean, geom="line") +
  facet_wrap(~ Participant)
ggplot(df_time, aes(x = Time, y = Prop, group = Condition, color=Condition)) +
  stat_summary(fun.y = mean, geom="line") +
  facet_wrap(~ Item)
```

### Consecutive t-tests, no correction:

```{r}
set.seed(5)
effect_start <- 2500
results <- bind_rows( pbreplicate(50, simplify = FALSE, expr = {
  df <- simulate_eyetrackingr_data(pref = .80, pref_window = c(effect_start,5000))
  df_time_sub <- make_time_sequence_data(df, time_bin_size = tb_size, predictor_columns = "Condition", aois = "AOI1", 
                                         summarize_by = "Participant")
  tb_anal <- analyze_time_bins(df_time_sub, predictor_column = "Condition", test = "t.test", alpha = .05, quiet=TRUE)
  tb_anal$Sig <- with(tb_anal, !is.na(PositiveRuns|NegativeRuns))
  with(tb_anal, 
       data.frame(false_alarm_bins = sum(Sig[Time <  effect_start-tb_size]),
            correct_discovery_bins = sum(Sig[Time >= effect_start]),
            first_discovery_time = Time[Time >= effect_start-tb_size & Sig][1],
            true_effect_onset = effect_start + 
              mean(describe_data(df, describe_column = "PrefOnset", group_columns = "Participant")[["Mean"]])
       ))
}) )

message("Sensitivity:")
message("Average Correct-Discovery Rate:", mean(results$correct_discovery_bins) / num_time_bins)
message("Rate of No Discovery: ", mean(results$correct_discovery_bins==0))
message("Average Time of First Divergence: ", mean(results$first_discovery_time, na.rm=TRUE))
message("Actual Time of Effect Onset: ", mean(results$true_effect_onset))
message("False Alarms")
message("Average FA Rate:", mean(results$false_alarm_bins) / num_time_bins)
message("Average FWER", mean(results$false_alarm_bins != 0))
```

### Consecutive t-tests, Bonferroni

```{r}
set.seed(5)
effect_start <- 2500
results <- bind_rows( pbreplicate(50, simplify = FALSE, expr = {
  df <- simulate_eyetrackingr_data(pref = .80, pref_window = c(effect_start,5000))
  df_time_sub <- make_time_sequence_data(df, time_bin_size = tb_size, predictor_columns = "Condition", aois = "AOI1", 
                                         summarize_by = "Participant")
  tb_anal <- analyze_time_bins(df_time_sub, predictor_column = "Condition", test = "t.test", alpha = .05/num_time_bins, quiet=TRUE)
  tb_anal$Sig <- with(tb_anal, !is.na(PositiveRuns|NegativeRuns))
  with(tb_anal, 
       data.frame(false_alarm_bins = sum(Sig[Time <  effect_start-tb_size]),
            correct_discovery_bins = sum(Sig[Time >= effect_start]),
            first_discovery_time = Time[Time >= effect_start-tb_size & Sig][1],
            true_effect_onset = effect_start + 
              mean(describe_data(df, describe_column = "PrefOnset", group_columns = "Participant")[["Mean"]])
       ))
}) )

message("Sensitivity:")
message("Average Correct-Discovery Rate:", mean(results$correct_discovery_bins) / num_time_bins)
message("Rate of No Discovery: ", mean(results$correct_discovery_bins==0))
message("Average Time of First Divergence: ", mean(results$first_discovery_time, na.rm=TRUE))
message("Actual Time of Effect Onset: ", mean(results$true_effect_onset))
message("False Alarms")
message("Average FA Rate:", mean(results$false_alarm_bins) / num_time_bins)
message("Average FWER", mean(results$false_alarm_bins != 0))
```
