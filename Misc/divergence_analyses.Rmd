---
title: "Testing Types of Divergence Analyses with Simulations"
author: "Jacob Dink"
date: "November 17, 2015"
output: html_document
---

## Prelims:
```{r}
stopifnot(grepl(pattern = "Misc", x = getwd()))
#devtools::install_github('jwdink/eyetrackingR')
library(eyetrackingR)
library(pbapply)
library(dplyr)
doMC::registerDoMC()
library(foreach)

# For 'quick' debugging:
# params_to_test_template <- expand.grid(NumSubjects = c(10),
#                                        NumItems    = c(10),
#                                        Pref        = c(.85),
#                                        SimNum      = 1:3)
# cluster_samples <- 25

boot_clusters <- FALSE # set to TRUE to run bootspline clusters

# For real:
params_to_test_template <- expand.grid(NumSubjects = c(10,30,60),
                                       NumItems    = c(10),
                                       Pref        = c(.65, .75, .85),
                                       SimNum      = 1:50)
cluster_samples <- 250


effect_start <- 2500
trial_length <- 5000
tb_size <- 100
num_time_bins <- trial_length / tb_size
num_no_effect_time_bins <- (effect_start/trial_length)*num_time_bins
num_effect_time_bins    <- (1-effect_start/trial_length)*num_time_bins
bootstrap_samples <- 1000
```

```{r}
make_time_data <- function(i, param_df) {
  df <- simulate_eyetrackingr_data(num_participants = param_df[i,"NumSubjects"], 
                                   num_items_per_condition = param_df[i,"NumItems"], 
                                   trial_length = trial_length, 
                                   pref = param_df[i,"Pref"],
                                   pref_window = c(effect_start, trial_length)
                                   )
  df_time <- make_time_sequence_data(data = df, time_bin_size = tb_size, aois = "AOI1", predictor_columns = "Condition", summarize_by = "Participant")
  return(df_time)
}
```

## T.Tests:

### Uncorrected:

```{r}
t_test_df <- params_to_test_template
t_test_df$Alpha <- .05
t_test_df$Test <- "t_test"
t_test_df$Adjustment <- ""
```

```{r}
if (!file.exists('sim_results/t_test_results.RDS')) {
  t_test_results <- pblapply(X = 1:nrow(t_test_df), FUN = function(i) {
    df_time <- make_time_data(i, t_test_df)
    tb_anal <- analyze_time_bins(df_time, predictor_column = "Condition", test = "t.test", alpha = t_test_df[i,"Alpha"], quiet=TRUE, formula=Elog ~ Condition)
    tb_anal$Sig <- with(tb_anal, !is.na(PositiveRuns|NegativeRuns))
    return(tb_anal)
  })
  saveRDS(t_test_results, file = "sim_results/t_test_results.RDS")
}
```

```{r}
t_test_results <- readRDS("sim_results/t_test_results.RDS")

for (i in seq_along(t_test_results)) {
  model <- t_test_results[[i]]
  # add to df:
  t_test_df[i,"FABins"] <- with(model, sum(Sig[Time <  effect_start]) )
  t_test_df[i,"CDBins"] <- with(model, sum(!is.na(PositiveRuns[Time >= effect_start])) )
  t_test_df[i,"FirstDiscTime"] <- with(model, Time[(Time >= effect_start) & !is.na(PositiveRuns)][1] )
}
```

### Bonf. Corrected

```{r}
t_test_bonf_df <- params_to_test_template
t_test_bonf_df$Alpha <- .05 / num_time_bins
t_test_bonf_df$Test <- "t_test"
t_test_bonf_df$Adjustment <- "bonferroni"
```

```{r}
if (!file.exists('sim_results/t_test_bonf_results.RDS')) {
  t_test_bonf_results <- pblapply(X = 1:nrow(t_test_bonf_df), FUN = function(i) {
    df_time <- make_time_data(i, t_test_bonf_df)
    tb_anal <- analyze_time_bins(df_time, predictor_column = "Condition", test = "t.test", alpha = t_test_bonf_df[i,"Alpha"], quiet=TRUE, formula=Elog ~ Condition)
    tb_anal$Sig <- with(tb_anal, !is.na(PositiveRuns|NegativeRuns))
    return(tb_anal)
  })
  saveRDS(t_test_bonf_results, file = "sim_results/t_test_bonf_results.RDS")
}
```

```{r}
t_test_bonf_results <- readRDS("sim_results/t_test_bonf_results.RDS")

for (i in seq_along(t_test_bonf_results)) {
  model <- t_test_bonf_results[[i]]
  # add to df:
  t_test_bonf_df[i,"FABins"] <- with(model, sum(Sig[Time <  effect_start]) )
  t_test_bonf_df[i,"CDBins"] <- with(model, sum(!is.na(PositiveRuns[Time >= effect_start])) )
  t_test_bonf_df[i,"FirstDiscTime"] <- with(model, Time[(Time >= effect_start) & !is.na(PositiveRuns)][1] )
}
```

## Boot-Splines:

### Uncorrected:

```{r}
boot_splines_df <- params_to_test_template
boot_splines_df$Alpha <- .05
boot_splines_df$Test <- "boot_splines"
boot_splines_df$Adjustment <- ""
```

```{r}
if (!file.exists('sim_results/boot_splines_results.RDS')) {
  boot_splines_results <- pblapply(X = 1:nrow(boot_splines_df), FUN = function(i) {
    df_time <- make_time_data(i, boot_splines_df)
    tb_anal <- analyze_time_bins(df_time, predictor_column = "Condition", test = "boot_splines", 
                                 samples = bootstrap_samples,
                                 within_subj = FALSE,
                                 alpha = boot_splines_df[i,"Alpha"], 
                                 quiet=TRUE)
    tb_anal$Sig <- with(tb_anal, !is.na(PositiveRuns|NegativeRuns))
    return(tb_anal)
  })
  saveRDS(boot_splines_results, file = "sim_results/boot_splines_results.RDS")
}
```

```{r}
boot_splines_results <- readRDS("sim_results/boot_splines_results.RDS")

for (i in seq_along(boot_splines_results)) {
  model <- boot_splines_results[[i]]
  # add to df:
  boot_splines_df[i,"FABins"] <- with(model, sum(Sig[Time <  effect_start]) )
  boot_splines_df[i,"CDBins"] <- with(model, sum(!is.na(PositiveRuns[Time >= effect_start])) )
  boot_splines_df[i,"FirstDiscTime"] <- with(model, Time[(Time >= effect_start) & !is.na(PositiveRuns)][1] )
}
```

### Bonf. Corrected:

```{r}
boot_splines_bonf_df <- params_to_test_template
boot_splines_bonf_df$Alpha <- .05  / num_time_bins
boot_splines_bonf_df$Test <- "boot_splines"
boot_splines_bonf_df$Adjustment <- "bonferroni"
```

```{r}
if (!file.exists('sim_results/boot_splines_bonf_results.RDS')) {
  boot_splines_bonf_results <- pblapply(X = 1:nrow(boot_splines_bonf_df), FUN = function(i) {
    df_time <- make_time_data(i, boot_splines_bonf_df)
    tb_anal <- analyze_time_bins(df_time, predictor_column = "Condition", test = "boot_splines", 
                                 samples = bootstrap_samples,
                                 within_subj = FALSE,
                                 alpha = boot_splines_bonf_df[i,"Alpha"], 
                                 quiet=TRUE)
    tb_anal$Sig <- with(tb_anal, !is.na(PositiveRuns|NegativeRuns))
    return(tb_anal)
  })
  saveRDS(boot_splines_bonf_results, file = "sim_results/boot_splines_bonf_results.RDS")
}
```

```{r}
boot_splines_bonf_results <- readRDS("sim_results/boot_splines_bonf_results.RDS")

for (i in seq_along(boot_splines_bonf_results)) {
  model <- boot_splines_bonf_results[[i]]
  # add to df:
  boot_splines_bonf_df[i,"FABins"] <- with(model, sum(Sig[Time <  effect_start]) )
  boot_splines_bonf_df[i,"CDBins"] <- with(model, sum(!is.na(PositiveRuns[Time >= effect_start])) )
  boot_splines_bonf_df[i,"FirstDiscTime"] <- with(model, Time[(Time >= effect_start) & !is.na(PositiveRuns)][1] )
}
```

## Cluster Analysis:

### Using t-tests, with Low. Threshold:

```{r}
time_cluster_low_thresh_df <- params_to_test_template
time_cluster_low_thresh_df$ThresholdAlpha <- .10
time_cluster_low_thresh_df$Alpha <- .05
time_cluster_low_thresh_df$Test <- "time_cluster_ttest"
time_cluster_low_thresh_df$Adjustment <- "low_threshold"
```

```{r}
if (!file.exists('sim_results/time_cluster_low_thresh_results.RDS')) {
  time_cluster_low_thresh_results <- foreach(i=1:nrow(time_cluster_low_thresh_df)) %dopar% {
    df_time <- make_time_data(i, time_cluster_low_thresh_df)
    cl_dat  <- make_time_cluster_data(df_time, predictor_column = "Condition", test = "t.test",
                                      formula = Elog ~ Condition,
                                      threshold = qt(p = time_cluster_low_thresh_df[i,"ThresholdAlpha"]/2, 
                                                     df = time_cluster_low_thresh_df[i,"NumSubjects"]) # <-- set thresh w/alpha
    )
    cl_anal <- analyze_time_clusters(cl_dat, within_subj = FALSE, samples = cluster_samples, parallel = TRUE)
    return(cl_anal)
  }
  saveRDS(time_cluster_low_thresh_results, file = "sim_results/time_cluster_low_thresh_results.RDS")
}
```

```{r}
time_cluster_low_thresh_results <- readRDS("sim_results/time_cluster_low_thresh_results.RDS")

for (i in seq_along(time_cluster_low_thresh_results)) {
  model <- get_time_clusters(time_cluster_low_thresh_results[[i]])
  
  if (nrow(model) > 0) {
    model <- model %>%
    mutate(Sig = Probability < .05,
           PreEffectTime = ifelse(effect_start-StartTime > 0, effect_start-StartTime, 0),
           ClusterStartTimeWithinEffect = ifelse(effect_start <= StartTime, StartTime, effect_start),
           DuringEffectTime = ifelse(EndTime >= effect_start, EndTime - ClusterStartTimeWithinEffect, 0),
           ClusterStartTimeWithinEffect = ifelse(DuringEffectTime==0, NA, ClusterStartTimeWithinEffect)) %>%
    filter(Sig)
    
    # add to df:
  time_cluster_low_thresh_df[i,"FABins"] <- with(model, sum(PreEffectTime) / tb_size)
  time_cluster_low_thresh_df[i,"CDBins"] <- with(model, sum(DuringEffectTime[Direction=="Positive"]) / tb_size)
  time_cluster_low_thresh_df[i,"FirstDiscTime"] <- with(model, ifelse(sum(!is.na(ClusterStartTimeWithinEffect))>0, yes = min(ClusterStartTimeWithinEffect,na.rm=T), no = NA))
  }
  else {
    time_cluster_low_thresh_df[i,"FABins"] <- 0
    time_cluster_low_thresh_df[i,"CDBins"] <- 0
    time_cluster_low_thresh_df[i,"FirstDiscTime"] <- NA
  }
}
```

### Using t-tests, with High. Threshold:

```{r}
time_cluster_high_thresh_df <- params_to_test_template
time_cluster_high_thresh_df$ThresholdAlpha <- .05
time_cluster_high_thresh_df$Alpha <- .05
time_cluster_high_thresh_df$Test <- "time_cluster_ttest"
time_cluster_high_thresh_df$Adjustment <- "high_threshold"
```

```{r}
if (!file.exists('sim_results/time_cluster_high_thresh_results.RDS')) {
  time_cluster_high_thresh_results <- foreach(i=1:nrow(time_cluster_high_thresh_df)) %dopar% {
    df_time <- make_time_data(i, time_cluster_high_thresh_df)
    cl_dat  <- make_time_cluster_data(df_time, predictor_column = "Condition", test = "t.test", 
                                      formula = Elog ~ Condition,
                                      threshold = qt(p = time_cluster_high_thresh_df[i,"ThresholdAlpha"]/2, 
                                                     df = time_cluster_high_thresh_df[i,"NumSubjects"]) # <-- set thresh w/alpha
    )
    cl_anal <- analyze_time_clusters(cl_dat, within_subj = FALSE, samples = cluster_samples, parallel = TRUE)
    return(cl_anal)
  }
  saveRDS(time_cluster_high_thresh_results, file = "sim_results/time_cluster_high_thresh_results.RDS")
}
```

```{r}
time_cluster_high_thresh_results <- readRDS("sim_results/time_cluster_high_thresh_results.RDS")

for (i in seq_along(time_cluster_high_thresh_results)) {
  model <- get_time_clusters(time_cluster_high_thresh_results[[i]])
  if (nrow(model) > 0) {
    model <- model %>%
      mutate(Sig = Probability < .05,
             PreEffectTime = ifelse(effect_start-StartTime > 0, effect_start-StartTime, 0),
             ClusterStartTimeWithinEffect = ifelse(effect_start <= StartTime, StartTime, effect_start),
             DuringEffectTime = ifelse(EndTime >= effect_start, EndTime - ClusterStartTimeWithinEffect, 0),
             ClusterStartTimeWithinEffect = ifelse(DuringEffectTime==0, NA, ClusterStartTimeWithinEffect)) %>%
      filter(Sig)
    
    # add to df:
    time_cluster_high_thresh_df[i,"FABins"] <- with(model, sum(PreEffectTime) / tb_size)
    time_cluster_high_thresh_df[i,"CDBins"] <- with(model, sum(DuringEffectTime[Direction=="Positive"]) / tb_size)
    time_cluster_high_thresh_df[i,"FirstDiscTime"] <- with(model, ifelse(sum(!is.na(ClusterStartTimeWithinEffect))>0, yes = min(ClusterStartTimeWithinEffect,na.rm=T), no = NA))
  }
  else {
    time_cluster_high_thresh_df[i,"FABins"] <- 0
    time_cluster_high_thresh_df[i,"CDBins"] <- 0
    time_cluster_high_thresh_df[i,"FirstDiscTime"] <- NA
  }
}
```

### Using boot-splines, with High. Threshold:

```{r}
if (boot_clusters == TRUE) {
  time_cluster_high_thresh_boot_df <- params_to_test_template_limited
  time_cluster_high_thresh_boot_df$ThresholdAlpha <- .05
  time_cluster_high_thresh_boot_df$Alpha <- .05
  time_cluster_high_thresh_boot_df$Test <- "time_cluster_boot"
  time_cluster_high_thresh_boot_df$Adjustment <- "high_threshold"
}
```

```{r}
if (boot_clusters == TRUE) {
  if (!file.exists('sim_results/time_cluster_high_thresh_boot_results.RDS')) {
    time_cluster_high_thresh_boot_results <- foreach(i=1:nrow(time_cluster_high_thresh_boot_df)) %dopar% {
      df_time <- make_time_data(i, time_cluster_high_thresh_boot_df)
      cl_dat  <- make_time_cluster_data(df_time, predictor_column = "Condition", test = "boot_splines", within_subj = FALSE, alpha = time_cluster_high_thresh_boot_df[i,"ThresholdAlpha"])
      cl_anal <- analyze_time_clusters(cl_dat, within_subj = FALSE, samples = cluster_samples,
                                       boot_samples = bootstrap_samples,
                                       parallel = TRUE)
      return(cl_anal)
    }
    saveRDS(time_cluster_high_thresh_boot_results, file = "sim_results/time_cluster_high_thresh_boot_results.RDS")
  }
}
```

```{r}
if (boot_clusters == TRUE) {
  time_cluster_high_thresh_boot_results <- readRDS("sim_results/time_cluster_high_thresh_boot_results.RDS")
  
  for (i in seq_along(time_cluster_high_thresh_boot_results)) {
    model <- get_time_clusters(time_cluster_high_thresh_boot_results[[i]])
    if (nrow(model) > 0) {
      model <- model %>%
        mutate(Sig = Probability < .05,
               PreEffectTime = ifelse(effect_start-StartTime > 0, effect_start-StartTime, 0),
               ClusterStartTimeWithinEffect = ifelse(effect_start <= StartTime, StartTime, effect_start),
               DuringEffectTime = ifelse(EndTime >= effect_start, EndTime - ClusterStartTimeWithinEffect, 0),
               ClusterStartTimeWithinEffect = ifelse(DuringEffectTime==0, NA, ClusterStartTimeWithinEffect)) %>%
        filter(Sig)
      
      # add to df:
      time_cluster_high_thresh_boot_df[i,"FABins"] <- with(model, sum(PreEffectTime) / tb_size)
      time_cluster_high_thresh_boot_df[i,"CDBins"] <- with(model, sum(DuringEffectTime[Direction=="Positive"]) / tb_size)
      time_cluster_high_thresh_boot_df[i,"FirstDiscTime"] <- with(model, ifelse(sum(!is.na(ClusterStartTimeWithinEffect))>0, yes = min(ClusterStartTimeWithinEffect,na.rm=T), no = NA))
    }
    else {
      time_cluster_high_thresh_boot_df[i,"FABins"] <- 0
      time_cluster_high_thresh_boot_df[i,"CDBins"] <- 0
      time_cluster_high_thresh_boot_df[i,"FirstDiscTime"] <- NA
    }
  }
}
```

## GCA:

```{r}
gca_df <- bind_rows(mutate(params_to_test_template, Adjustment = ""),
                    mutate(params_to_test_template, Adjustment = "FWER_Correction") ) %>%
  arrange(SimNum) %>% as.data.frame()
gca_df$Alpha <- .05
gca_df$Test <- "gca"
```

```{r}
library("Matrix")
library("lme4")
if (!file.exists('sim_results/gca_results.RDS')) {
  gca_results <- pblapply(1:nrow(gca_df), function(i) {
    df <- simulate_eyetrackingr_data(num_participants = gca_df[i,"NumSubjects"], 
                                     num_items_per_condition = gca_df[i,"NumItems"], 
                                     trial_length = trial_length, 
                                     pref = gca_df[i,"Pref"],
                                     pref_window = c(effect_start, trial_length)
    )
    df$ConditionC <- ifelse(df$Condition=="High", .5, -.5)
    df_time <- make_time_sequence_data(data = df, time_bin_size = tb_size, aois = "AOI1", predictor_columns = "ConditionC", summarize_by = "Participant")
    
    # whole window:
    gca_anal_whole_window <- lmer(Elog ~ (ot1+ot2+ot3)*ConditionC + (1+ot1+ot2+ot3|Participant), data = df_time)
    
    # no effect window (look for FAs):
    df_time_no_effect_window <- df %>%
      filter(TimeInTrial < effect_start) %>% 
      make_time_sequence_data(time_bin_size = tb_size, aois = "AOI1", predictor_columns = "ConditionC",
                                       summarize_by = "Participant")
      gca_anal_no_effect_window <- lmer(Elog ~ (ot1+ot2+ot3)*ConditionC + (1+ot1+ot2+ot3|Participant), 
                                      data= df_time_no_effect_window)
    
    return(list(whole_window = gca_anal_whole_window, no_effect_window = gca_anal_no_effect_window))
  })
  saveRDS(gca_results, file = "sim_results/gca_results.RDS")
}
```

```{r}
gca_results <- readRDS("sim_results/gca_results.RDS")

for (i in seq_along(gca_results)) {
  threshold = ifelse(gca_df[i, "Adjustment"] == "FWER_Correction", 
                     yes = qnorm(p = 1-gca_df[i, "Alpha"]/8 ), # <---- four params are being considered
                     no  = qnorm(p = 1-gca_df[i, "Alpha"]/2 )) 
  
  # Whole Window (CD):
  model_whole_window <- gca_results[[i]][["whole_window"]]
  model_whole_window_df <- broom::tidy(model_whole_window, effects="fixed")
  found_effect <- with(model_whole_window_df, any( 
    statistic[term %in% c("ConditionC", "ot1:ConditionC", "ot1:ConditionC", "ot1:ConditionC")] >= threshold ) )
  gca_df[i, "CDBins"] <- ifelse(found_effect, num_effect_time_bins, 0)
  
  # No-effect Window (FA):
  model_no_effect_window <- gca_results[[i]][["no_effect_window"]]
  model_no_effect_window_df <- broom::tidy(model_no_effect_window, effects="fixed")
  false_alarmed <- with(model_no_effect_window_df, any( 
    statistic[term %in% c("ConditionC", "ot1:ConditionC", "ot1:ConditionC", "ot1:ConditionC")] >= threshold ) )
  gca_df[i, "FABins"] <- ifelse(false_alarmed, num_no_effect_time_bins, 0)
}
```

# Visualizations

```{r}
library("ggplot2")
get_mean_ci <- function(vec) {
  if (length(vec)<1) return("NA, NA, NA")
  if (all(is.na(vec))) return("NA, NA, NA")
  if (all(diff(vec)==0, na.rm=TRUE)) return(paste(rep(mean(vec, na.rm=TRUE),3), collapse = ", "))
  bootstrapped <- boot::boot(vec, function(x,i) mean(x[i],na.rm=TRUE), 500)
  paste(c(mean(vec,na.rm=TRUE), boot::boot.ci( bootstrapped, type="perc")$percent[4:5]), collapse = ", " )
}

master_df <- bind_rows(boot_splines_bonf_df, boot_splines_df, 
                       t_test_bonf_df, t_test_df, 
                       time_cluster_low_thresh_df, time_cluster_high_thresh_df,
                       gca_df) %>%
  filter(!is.na(FABins)) # <-------------
master_df$Test <- factor(master_df$Test, 
                         levels = c("t_test", "boot_splines", "gca", "time_cluster_ttest","time_cluster_boot"))
master_df$TestType <- with(master_df, 
                           factor(x = ifelse(Adjustment != '',paste0(Test, ' (', Adjustment, ')'),stringr::str_trim(Test)), 
                                  levels = c('t_test', 't_test (bonferroni)', 
                                             'boot_splines', 'boot_splines (bonferroni)', 
                                             'gca', 'gca (FWER_Correction)', 
                                             'time_cluster_ttest (low_threshold)', 'time_cluster_ttest (high_threshold)')
                           ))
## TO DO ## make these not ugly as sin
pallette <- c("#E69F00", "#9e6c00", 
              "#56B4E9", "#1778b0", 
              "#009E73", "#005c43", 
              "#F0E442", "#b8ad0f") 
names(pallette) <- levels(master_df$TestType) # I don't know if this does anything

make_graph <- function(g) {
  g + 
    scale_fill_manual(values = pallette) +
    geom_bar(position = position_dodge(), stat="identity") +
    geom_linerange(position = position_dodge(width=.9), aes(ymin = CI_Low, ymax = CI_High)) +
    theme_bw() + coord_cartesian(ylim=c(0,1))
}
```

```{r}
summary_per_cell_fa <- master_df %>%
  group_by(NumSubjects, NumItems, Alpha, Test, Adjustment, TestType) %>%  # <--- does not include pref
  summarise(ErrorRate    = get_mean_ci(FABins/num_no_effect_time_bins),
            FWER         = get_mean_ci(FABins != 0)) %>%
  tidyr::gather(key = "Measure", value = "Value", ErrorRate,FWER) %>%
  tidyr::separate(col = Value, sep = ", ", into = c("Mean", "CI_Low", "CI_High"), remove = TRUE) %>%
  mutate(Mean = as.numeric(Mean), CI_Low = as.numeric(CI_Low), CI_High = as.numeric(CI_High))

ggplot(filter(summary_per_cell_fa, Measure=="FWER"), aes(x=Test, y=Mean, fill=TestType)) %>%
  make_graph() + scale_y_continuous(name='FWER') +facet_grid(. ~ NumSubjects)

ggplot(filter(summary_per_cell_fa, Measure=="ErrorRate"), aes(x=Test, y=Mean, fill=TestType)) %>%
  make_graph() + scale_y_continuous(name='ErrorRate') + facet_grid(. ~ NumSubjects)

# Brock's megaplot
summary_per_cell_fa$NumSubjectsText <- paste0('N = ',summary_per_cell_fa$NumSubjects)

# get rid of GCA
summary_per_cell_fa_brock <- filter(summary_per_cell_fa, Test != 'gca')

p <- ggplot(summary_per_cell_fa_brock, aes(x=Measure, y=Mean, fill=TestType)) %>%
  make_graph() + scale_y_continuous(name='Proportion') +
  scale_x_discrete(labels=c('ER','FWER')) +
  geom_hline(yintercept=.05,linetype="dashed") +
  facet_wrap( ~ NumSubjectsText)

png(filename = "plot-false-alarms.png",
    width = 4000, height = 1100, units = "px", pointsize = 16,
    bg = "white", res = 400)
p
dev.off()
p
```

```{r}
summary_per_cell_dr <- master_df %>%
  group_by(NumSubjects, NumItems, Pref, Alpha, Test, Adjustment, TestType) %>% # <----- includes pref
  summarise(DiscoveryRate = get_mean_ci(CDBins/num_effect_time_bins),
            FWDR         = get_mean_ci(CDBins != 0),
            FalseDiscoveryRate = get_mean_ci( (FABins/num_no_effect_time_bins) / 
                                               ((CDBins/num_effect_time_bins) + (FABins/num_no_effect_time_bins)))) %>%
  tidyr::gather(key = "Measure", value = "Value", DiscoveryRate:FalseDiscoveryRate) %>%
  tidyr::separate(col = Value, sep = ", ", into = c("Mean", "CI_Low", "CI_High"), remove = TRUE) %>%
  mutate(Mean = as.numeric(Mean), CI_Low = as.numeric(CI_Low), CI_High = as.numeric(CI_High))

ggplot(filter(summary_per_cell_dr, Measure=="FWDR"), aes(x=Test, y=Mean, fill=TestType)) %>%
  make_graph() + scale_y_continuous(name='FWDR') +facet_grid(Pref ~ NumSubjects)

ggplot(filter(summary_per_cell_dr, Measure=="DiscoveryRate"), aes(x=Test, y=Mean, fill=TestType)) %>%
  make_graph() + scale_y_continuous(name='DiscoveryRate') + facet_grid(Pref ~ NumSubjects)

# Brock's megaplot
summary_per_cell_dr$NumSubjectsText <- paste0('N = ',summary_per_cell_dr$NumSubjects)
summary_per_cell_dr$PrefText <- paste0('diff = ', summary_per_cell_dr$Pref - .5)

# get rid of GCA
summary_per_cell_dr_brock <- filter(summary_per_cell_dr, Test != 'gca')

p <- ggplot(summary_per_cell_dr_brock, aes(x=Measure, y=Mean, fill=TestType)) %>%
  make_graph() + scale_y_continuous(name='Proportion') +
  scale_x_discrete(labels=c('DR','FWDR','FDR')) +
  geom_hline(yintercept=.80,linetype="dashed") +
  geom_hline(yintercept=.05,linetype="dashed") +
  facet_wrap( ~ NumSubjectsText+PrefText)

png(filename = "plot-discoveries.png",
    width = 4000, height = 2900, units = "px", pointsize = 16,
    bg = "white", res = 400)
p
dev.off()
p
```

```{r}
summary_overall <- master_df %>%
  group_by(NumItems, Alpha, Test, Adjustment, TestType) %>%
  summarise(ErrorRate    = get_mean_ci(FABins/num_no_effect_time_bins),
            FWER         = get_mean_ci(FABins != 0),
            DiscoveryRate = get_mean_ci(CDBins/num_effect_time_bins),
            FWDR         = get_mean_ci(CDBins != 0),
            FalseDiscoveryRate = get_mean_ci( (FABins/num_no_effect_time_bins) / 
                                               ((CDBins/num_effect_time_bins) + (FABins/num_no_effect_time_bins)))
  ) %>%
  tidyr::gather(key = "Measure", value = "Value", ErrorRate:FalseDiscoveryRate) %>%
  tidyr::separate(col = Value, sep = ", ", into = c("Mean", "CI_Low", "CI_High"), remove = TRUE) %>%
  mutate(Mean = as.numeric(Mean), CI_Low = as.numeric(CI_Low), CI_High = as.numeric(CI_High))

summary_overall <- filter(summary_overall, !Test %in% c("time_cluster_boot") ) # remove when we have data here

# add dashed lines
summary_overall <- summary_overall %>%
                   mutate(DashedLine = ifelse(Measure %in% c('ErrorRate','FWER','FalseDiscoveryRate'), .05, .80))

ggplot(summary_overall, aes(x = Test, y = Mean, fill = TestType)) %>%
  make_graph() + scale_y_continuous(name = "Proportion") +
  geom_hline(aes(yintercept=DashedLine), linetype='dashed') +
  facet_grid(Measure ~ .)

# make easier to read summary
summary_overall_wide <- master_df %>%
                    group_by(NumItems, Alpha, Test, Adjustment, TestType) %>%
                    summarise(ErrorRate    = mean(FABins/num_no_effect_time_bins),
                              FWER         = mean(FABins != 0),
                              DiscoveryRate = mean(CDBins/num_effect_time_bins),
                              FWDR         = mean(CDBins != 0),
                              FalseDiscoveryRate = mean( (FABins/num_no_effect_time_bins) / 
                                                                   ((CDBins/num_effect_time_bins) + (FABins/num_no_effect_time_bins)))
                    )

summary_overall_wide
```
