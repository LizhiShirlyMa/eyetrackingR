---
title: "Testing Properties of Divergence Analyses with Simulations"
author: "Jacob Dink"
date: "November 15, 2015"
output: html_document
---

### Notes/Brainstorming:

wrap each of the tests below in a for loop that varies
* sample-size (both subjects, items)
* effect-size
* length of trial

other things to check:
[x] Any divergence?
[x] Total prop of divergence time?
[ ] Magnitude of divergence?
[ ] Average distance between cluster and bootstrapped? 

### Example Fake Data with No Effect

No preference for either AOI (5 second trial, N=16, 6 items per participant, between subjects)

```{r}
library("eyetrackingR")
library("ggplot2")
library("dplyr")
library("pbapply")

set.seed(40)
tb_size = 250

df <- simulate_eyetrackingr_data()
describe_data(df, describe_column = "AOI1", group_columns = c("Condition","Participant","Item"))
df_time <- make_time_sequence_data(df, time_bin_size = tb_size, predictor_columns = "Condition", aois = "AOI1")
plot(df_time, predictor_column = "Condition")

##
ggplot(df_time, aes(x = Time, y = Prop, group = Condition, color=Condition)) +
  stat_summary(fun.y = mean, geom="line") +
  facet_wrap(~ Participant)

ggplot(df_time, aes(x = Time, y = Prop, group = Condition, color=Condition)) +
  stat_summary(fun.y = mean, geom="line") +
  facet_wrap(~ Item)

num_time_bins <- length(unique(df_time$TimeBin))
```

### Example Fake Data with Effect

A strong preference for AOI1 in the "high" condition emerges halfway through the trial (5 second trial, N=16, 6 items per participant, between subjects).

```{r}
set.seed(48)
df <- simulate_eyetrackingr_data(pref = .80, pref_window = c(2500,5000))
df_time <- make_time_sequence_data(df, time_bin_size = tb_size, predictor_columns = "Condition", aois = "AOI1")
plot(df_time, predictor_column = "Condition")

##
ggplot(df_time, aes(x = Time, y = Prop, group = Condition, color=Condition)) +
  stat_summary(fun.y = mean, geom="line") +
  facet_wrap(~ Participant)
ggplot(df_time, aes(x = Time, y = Prop, group = Condition, color=Condition)) +
  stat_summary(fun.y = mean, geom="line") +
  facet_wrap(~ Item)
```

## T.Tests

### No Correction:

```{r}
set.seed(5)
effect_start <- 2500
results1 <- bind_rows( pbreplicate(50, simplify = FALSE, expr = {
  df <- simulate_eyetrackingr_data(pref = .80, pref_window = c(effect_start,5000))
  df_time_sub <- make_time_sequence_data(df, time_bin_size = tb_size, predictor_columns = "Condition", aois = "AOI1", 
                                         summarize_by = "Participant")
  tb_anal <- analyze_time_bins(df_time_sub, predictor_column = "Condition", test = "t.test", alpha = .05, quiet=TRUE)
  tb_anal$Sig <- with(tb_anal, !is.na(PositiveRuns|NegativeRuns))
  with(tb_anal, 
       data.frame(false_alarm_bins = sum(Sig[Time <  effect_start-tb_size]),
            correct_discovery_bins = sum(Sig[Time >= effect_start]),
            first_discovery_time = Time[Time >= effect_start-tb_size & Sig][1],
            true_effect_onset = effect_start + 
              mean(describe_data(df, describe_column = "PrefOnset", group_columns = "Participant")[["Mean"]])
       ))
}) )

cat(
  "\nSensitivity:",
  "\n\tAverage Correct-Discovery Rate:\t", mean(results1$correct_discovery_bins) / num_time_bins,
  "\n\tRate of No Discovery:\t\t ", mean(results1$correct_discovery_bins==0),
  "\n\tAverage Time of 1st Divergence:\t", mean(results1$first_discovery_time, na.rm=TRUE),
  "\n\tActual Time of Effect Onset:\t", mean(results1$true_effect_onset),
  "\nFalse Alarms:",
  "\n\tAverage FA Rate:\t", mean(results1$false_alarm_bins) / num_time_bins,
  "\n\tAverage FWER:\t\t", mean(results1$false_alarm_bins != 0)
)
```

### Bonf. correction:

```{r}
set.seed(5)
effect_start <- 2500
results2 <- bind_rows( pbreplicate(50, simplify = FALSE, expr = {
  df <- simulate_eyetrackingr_data(pref = .80, pref_window = c(effect_start,5000))
  df_time_sub <- make_time_sequence_data(df, time_bin_size = tb_size, predictor_columns = "Condition", aois = "AOI1", 
                                         summarize_by = "Participant")
  tb_anal <- analyze_time_bins(df_time_sub, predictor_column = "Condition", test = "t.test", alpha = .05/num_time_bins, quiet=TRUE)
  tb_anal$Sig <- with(tb_anal, !is.na(PositiveRuns|NegativeRuns))
  with(tb_anal, 
       data.frame(false_alarm_bins = sum(Sig[Time <  effect_start-tb_size]),
            correct_discovery_bins = sum(Sig[Time >= effect_start]),
            first_discovery_time = Time[Time >= effect_start-tb_size & Sig][1],
            true_effect_onset = effect_start + 
              mean(describe_data(df, describe_column = "PrefOnset", group_columns = "Participant")[["Mean"]])
       ))
}) )

cat(
  "\nSensitivity:",
  "\n\tAverage Correct-Discovery Rate:\t", mean(results2$correct_discovery_bins) / num_time_bins,
  "\n\tRate of No Discovery:\t\t ", mean(results2$correct_discovery_bins==0),
  "\n\tAverage Time of 1st Divergence:\t", mean(results2$first_discovery_time, na.rm=TRUE),
  "\n\tActual Time of Effect Onset:\t", mean(results2$true_effect_onset),
  "\nFalse Alarms:",
  "\n\tAverage FA Rate:\t", mean(results2$false_alarm_bins) / num_time_bins,
  "\n\tAverage FWER:\t\t", mean(results2$false_alarm_bins != 0)
)
```

## Boot-Splines

### No Correction:

```{r}
set.seed(5)
effect_start <- 2500
results3 <- bind_rows( pbreplicate(50, simplify = FALSE, expr = {
  df <- simulate_eyetrackingr_data(pref = .80, pref_window = c(effect_start,5000))
  df_time_sub <- make_time_sequence_data(df, time_bin_size = tb_size, predictor_columns = "Condition", aois = "AOI1", 
                                         summarize_by = "Participant")
  bs_dat <- make_boot_splines_data(df_time_sub, predictor_column = "Condition", within_subj = FALSE, alpha = .05, samples = 250)
  bs_anal <- analyze_boot_splines(bs_dat)
  with(bs_anal, 
       data.frame(false_alarm_bins = sum(Significant[Time <  effect_start-tb_size]),
            correct_discovery_bins = sum(Significant[Time >= effect_start]),
            first_discovery_time = Time[Time >= effect_start-tb_size & Significant][1],
            true_effect_onset = effect_start + 
              mean(describe_data(df, describe_column = "PrefOnset", group_columns = "Participant")[["Mean"]])
       ))
}) )

cat(
  "\nSensitivity:",
  "\n\tAverage Correct-Discovery Rate:\t", mean(results3$correct_discovery_bins) / num_time_bins,
  "\n\tRate of No Discovery:\t\t ", mean(results3$correct_discovery_bins==0),
  "\n\tAverage Time of 1st Divergence:\t", mean(results3$first_discovery_time, na.rm=TRUE),
  "\n\tActual Time of Effect Onset:\t", mean(results3$true_effect_onset),
  "\nFalse Alarms:",
  "\n\tAverage FA Rate:\t", mean(results3$false_alarm_bins) / num_time_bins,
  "\n\tAverage FWER:\t\t", mean(results3$false_alarm_bins != 0)
)
```

### Bonf. Correction:

```{r}
set.seed(8)
effect_start <- 2500
results4 <- bind_rows( pbreplicate(50, simplify = FALSE, expr = {
  df <- simulate_eyetrackingr_data(pref = .80, pref_window = c(effect_start,5000))
  df_time_sub <- make_time_sequence_data(df, time_bin_size = tb_size, predictor_columns = "Condition", aois = "AOI1", 
                                         summarize_by = "Participant")
  bs_dat <- make_boot_splines_data(df_time_sub, predictor_column = "Condition", within_subj = FALSE, alpha = .05/num_time_bins, 
                                   samples = 250)
  bs_anal <- analyze_boot_splines(bs_dat)
  with(bs_anal, 
       data.frame(false_alarm_bins = sum(Significant[Time <  effect_start-tb_size]),
            correct_discovery_bins = sum(Significant[Time >= effect_start]),
            first_discovery_time = Time[Time >= effect_start-tb_size & Significant][1],
            true_effect_onset = effect_start + 
              mean(describe_data(df, describe_column = "PrefOnset", group_columns = "Participant")[["Mean"]])
       ))
}) )

cat(
  "\nSensitivity:",
  "\n\tAverage Correct-Discovery Rate:\t", mean(results4$correct_discovery_bins) / num_time_bins,
  "\n\tRate of No Discovery:\t\t ", mean(results4$correct_discovery_bins==0),
  "\n\tAverage Time of 1st Divergence:\t", mean(results4$first_discovery_time, na.rm=TRUE),
  "\n\tActual Time of Effect Onset:\t", mean(results4$true_effect_onset),
  "\nFalse Alarms:",
  "\n\tAverage FA Rate:\t", mean(results4$false_alarm_bins) / num_time_bins,
  "\n\tAverage FWER:\t\t", mean(results4$false_alarm_bins != 0)
)
```